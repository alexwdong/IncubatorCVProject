{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "dataloader.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s64vOJB1JnBR",
        "colab_type": "text"
      },
      "source": [
        "### Set access to google drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3E6EaNKkhpD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "136da09e-af6b-45eb-a1ca-9538a84a6063"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Xc3-VtGkkx5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad00c64c-87f5-4ad8-f55d-d6ebfcfd495a"
      },
      "source": [
        "%cd drive/My\\ Drive/CV_incubator/IncubatorCVProject"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/CV_incubator/IncubatorCVProject\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxHJxNbbXASb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1bad036d-4e83-4e3a-911e-fdf336a7c66a"
      },
      "source": [
        "!ls src"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Basic_CNN_Architecture.py   data_loader.py\t    main_two.py  train_valid.py\n",
            "BasicCNN_withfeat_64x64.py  feature_engineering.py  __pycache__  utils.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qwEBOXdJr7v",
        "colab_type": "text"
      },
      "source": [
        "### Import libraries and setup paths\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5aE_NqOkeXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from src.data_loader import SquarePadding\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor,Resize,Compose\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import torch\n",
        "import inspect\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "from PIL import Image\n",
        "from src.feature_engineering import prepare_spectral_clustering_features,prepare_eigen_component_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I09ueuoVkeXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Path to image folder and label.csv\n",
        "data_path = '../dog-breed-identification'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hP-8IIswGWtM",
        "colab_type": "text"
      },
      "source": [
        "### Data loader\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpODzqDxMJji",
        "colab_type": "text"
      },
      "source": [
        "Map image path to label and label index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUacai2Psd6H",
        "colab_type": "text"
      },
      "source": [
        "### Combining with engineered features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q4_75KIscZQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from src.data_loader import load_dog_data\n",
        "from sklearn.decomposition import PCA\n",
        "from src.utils import PCA_images_list, unravel_image, ravel_image_vec, plot_image_grid\n",
        "import numpy as np\n",
        "import pickle\n",
        "from src.feature_engineering import prepare_eigen_component_features\n",
        "import torch\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5yMSA7SvqVR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(image_list,label_list,label_dict) = load_dog_data(data_path,\n",
        "              image_shape=(64,64),\n",
        "              sample_rate=1, \n",
        "              simple=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UAV21fuvsMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(eig_vals,eig_image_list) = PCA_images_list(image_list)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heyQwBXvipg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump( (eig_vals,eig_image_list), open( \"eigvalsvecs.p\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjM75hpUGQj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(image_list, open( \"image_list.p\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiM9YmSlYT2Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file = open('eigvalsvecs.p', 'rb')\n",
        "eigen = pickle.load(file)\n",
        "eig_vecs = eigen[1][-300:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6snDKKQCGCky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_eigen_component_features(images_list,eig_vecs):\n",
        "    '''\n",
        "    Inputs:\n",
        "        images_list: list of images (images are ndarrays, usually of 2 dimensions (e.g 128x128))\n",
        "        eig_vecs: an 2d array of eigenvectors, where each eigenvector is a column\n",
        "    Outputs:\n",
        "        return: returns a feature matrix, where the rows of the feature matrix correspond to the \n",
        "        features of images. First image is the first row of the matrix, last image is the last row.\n",
        "        The features are the components of the eigenvectors (which were passed in the input 'eig_vecs')\n",
        "    '''\n",
        "    #n_components = len(eig_vecs.shape)\n",
        "    image_list = torch.Tensor(images_list)\n",
        "    feat = torch.Tensor(eig_vecs)\n",
        "    feat = torch.transpose(torch.flatten(feat,1),0,1)\n",
        "    image_vec = torch.flatten(image_list,1)\n",
        "    feature_matrix = image_vec@feat\n",
        "        \n",
        "    return feature_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuRXXUHDHqpX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dddd9b86-82d6-480f-a6c3-ab78cc518d6d"
      },
      "source": [
        "image_vec = torch.flatten(torch.Tensor(image_list),1)\n",
        "torch.transpose(image_vec,0,1).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4096, 10222])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQZGJk8foKSM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "97cc5ec3-4c28-4b69-fcae-4990c3e8478b"
      },
      "source": [
        "features = prepare_eigen_component_features(image_list,eig_vecs)\n",
        "print(features.size())\n",
        "pickle.dump( features, open( \"features.p\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10222, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead\n",
            "  warnings.warn(\"pickle support for Storage will be removed in 1.5. Use `torch.save` instead\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIBOsLs1KgwP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1bf40035-defc-4304-83c0-7a5463fe0c72"
      },
      "source": [
        "file = open('features.p', 'rb')\n",
        "features = pickle.load(file)\n",
        "features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10222, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbu0uwdvo4Na",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_feat = valid_feat = features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7pSgWqNOOJh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59831047-4244-405a-c4e9-76e7eca570b2"
      },
      "source": [
        "torch.flatten(features).size()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3066600])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    }
  ]
}