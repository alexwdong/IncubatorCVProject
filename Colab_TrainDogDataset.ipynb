{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Colab_TrainDogDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGrt6BJRBTGU",
        "colab_type": "text"
      },
      "source": [
        "# Directions 0a: \n",
        "First mount your google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De07ekFZsOvy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "e1a8b983-95f0-4d83-d228-2114789c7835"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDwihXNz2HFV",
        "colab_type": "text"
      },
      "source": [
        "# Directions 0b: Github pull, you only need to do this once! \n",
        "Use the next two cells to cd into a working directory where you will pull the github repo into.\n",
        " The directory that I used looked like\n",
        "\n",
        " \"/content/drive/My Drive/\"\n",
        " \n",
        "I then used the second cell to clone the (specific branch) of the github repo.\n",
        "Note that on line 10, you can adjust to command to pull specific branches/pull\n",
        "the master."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JE6uFX6ntbos",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6910733a-c503-4645-d6f5-b05f1f573782"
      },
      "source": [
        "% cd drive/My\\ Drive/IncubatorCVProject"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IncubatorCVProject\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaUMFUCLtOgp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "import urllib\n",
        "\n",
        "user = input('User name: ')\n",
        "password = getpass('Password: ')\n",
        "password = urllib.parse.quote(password) # your password is converted into url format\n",
        "repo_name = input('Repo name: ')\n",
        "\n",
        "cmd_string = 'git clone -b combine https://{0}:{1}@github.com/{0}/{2}.git'.format(user, password, repo_name)\n",
        "\n",
        "os.system(cmd_string)\n",
        "cmd_string, password = \"\", \"\" # removing the password from the variable"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqU0OETOnyU2",
        "colab_type": "text"
      },
      "source": [
        "# Directions 1: Move the data to colab locally\n",
        "Download the data from this website:\n",
        " https://www.kaggle.com/jessicali9530/stanford-dogs-dataset, and upload it to your google drive. Then use the following cell to unrar it into your /content folder. The /content folder is local to colab, which is important for loading the data in a timely manner.\n",
        "\n",
        "\n",
        " !!!Note!!!: There are multiple versions of this dataset out there that are in different formats! Please download the dataset from this website.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRNKtjt8tMCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content\n",
        "%unrar x /content/drive/My\\ Drive/DogsDataset.rar\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dZWz1jd1sTC",
        "colab_type": "text"
      },
      "source": [
        "Directions 2: Change directory back into the github, so that you can load python modules that we wrote"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hwPqWtnycE8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "58b9159f-7a5a-4752-cf7e-6b9995b21706"
      },
      "source": [
        "%cd /content/drive/My\\ Drive/IncubatorCVProject"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IncubatorCVProject\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeSXe4P617E5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "898634c8-12e7-4329-e589-cf20332cbb96"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/IncubatorCVProject\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhCBpgzjBczd",
        "colab_type": "text"
      },
      "source": [
        "# Now run your notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPA2wX4P49Lm",
        "colab_type": "text"
      },
      "source": [
        "### Edit paths in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkJQcCQX422A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = r'/content/DogsDataset/images/Images'\n",
        "best_models_path = r'/drive/My\\ Drive/best_models/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmTuyVGqprxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################\n",
        "############# Notice ##############\n",
        "###################################\n",
        "\n",
        "# Some parts need to be adapted later\n",
        "\n",
        "###################################\n",
        "########## import library #########\n",
        "###################################\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import ToTensor,Resize,Compose\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "import time\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.train_valid import train, validation\n",
        "from src.Basic_CNN_Architecture import BasicCNN_128x128\n",
        "from src.data_loader import load_dog_data,SquarePadding\n",
        "from src.utils import unravel_image"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8Nj0EoXprxb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d83aba4-78e1-4b58-dca0-bef813ddd56b"
      },
      "source": [
        "\n",
        "###################################\n",
        "########### load device ###########\n",
        "###################################\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():\n",
        "\n",
        "    # Tell PyTorch to use the GPU.\n",
        "    device = torch.device(\"cuda\")\n",
        "    \n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcrwnRtTprxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "###################################\n",
        "############ def path #############\n",
        "###################################\n",
        "\n",
        "# hpc\n",
        "# please change file path here\n",
        "        \n",
        "\n",
        "#val_df_path =\n",
        "#test_df_path =\n",
        "#root_dir =\n",
        "\n",
        "\n",
        "\n",
        "#Put your data path here\n",
        "#data_path = r'/content/DogsDataset/images/Images'\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjPWXO-wprxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################\n",
        "############ load data ############\n",
        "###################################\n",
        "\n",
        "# after feature engineering(task 3)\n",
        "\n",
        "#Variables for splitting the dataset into train/test\n",
        "valid_split = .1\n",
        "test_split = .1\n",
        "batch_size = 16\n",
        "shuffle_dataset = True\n",
        "random_seed = 42\n",
        "\n",
        "#Load initial dataset\n",
        "dog_dataset = ImageFolder(data_path,transform=Compose([\n",
        "    SquarePadding(),\n",
        "    Resize((128,128)),\n",
        "    ToTensor()\n",
        "])) \n",
        "# Split \n",
        "dataset_size = len(dog_dataset)\n",
        "indices = list(range(dataset_size))\n",
        "split_idx1 = int(np.floor((valid_split+test_split) * dataset_size))\n",
        "split_idx2 = int(np.floor(test_split * dataset_size))\n",
        "if shuffle_dataset:\n",
        "    np.random.seed(random_seed)\n",
        "    np.random.shuffle(indices)\n",
        "    \n",
        "test_indices, valid_indices, train_indices = indices[:split_idx2], indices[split_idx2:split_idx1], indices[split_idx1:]\n",
        "\n",
        "# Creating PT data samplers and loaders:\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "valid_sampler = SubsetRandomSampler(valid_indices)\n",
        "test_sampler = SubsetRandomSampler(test_indices)\n",
        "\n",
        "#Load Train, valid, test         \n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if device=='cuda' else {} \n",
        "train_loader = torch.utils.data.DataLoader(dog_dataset, batch_size=batch_size, \n",
        "                                           sampler=train_sampler,**kwargs)\n",
        "valid_loader = torch.utils.data.DataLoader(dog_dataset, batch_size=batch_size,\n",
        "                                                sampler=valid_sampler,**kwargs)\n",
        "test_loader =  torch.utils.data.DataLoader(dog_dataset, batch_size=batch_size,\n",
        "                                                sampler=test_sampler,**kwargs)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYI0ofG-prxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "79e98cc2-93bb-4a40-96a5-a212bc9728ed"
      },
      "source": [
        "###################################\n",
        "############ Train ############\n",
        "###################################\n",
        "print('###################################')\n",
        "print('############## Train ##############')\n",
        "print('###################################')\n",
        "\n",
        "# training process\n",
        "# to be finished later\n",
        "model = BasicCNN_128x128(num_classes=len(dog_dataset.classes),\n",
        "                        )\n",
        "model.to(device)\n",
        "train_loss = nn.CrossEntropyLoss()\n",
        "train_loss.to(device)\n",
        "valid_loss = nn.CrossEntropyLoss()\n",
        "valid_loss.to(device)\n",
        "def train_valid(optimizer = optim.Adam(model.parameters()), epochs = 20, model = model,\n",
        "                train_criterion = train_loss, train_loader = train_loader,\n",
        "                valid_criterion = valid_loss, valid_loader = valid_loader,\n",
        "                device = device):\n",
        "\n",
        "    start_epoch = 1\n",
        "    #or: best_val_acc = 0\n",
        "    best_val_loss = np.inf\n",
        "\n",
        "    history = {\"train_loss\":[], \"train_acc\":[],\n",
        "                \"valid_loss\":[], \"valid_acc\":[], \"valid_preds_list\":[],\n",
        "                \"valid_truelabels_list\":[], \"valid_probas_list\":[], \"valid_auc_score\":[]}\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(start_epoch, epochs + 1):\n",
        "\n",
        "        train_loss, train_acc = train(epoch, model, optimizer, train_criterion, train_loader, device)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "\n",
        "        print('epoch: ', epoch)\n",
        "        print('{}: loss: {:.4f} acc: {:.4f}'.format('training', train_loss, train_acc))\n",
        "\n",
        "        valid_loss, valid_acc, valid_preds_list, valid_truelabels_list, valid_probas_list, valid_auc_score = validation(epoch, model, optimizer, valid_criterion, valid_loader, device)\n",
        "        history[\"valid_loss\"].append(valid_loss)\n",
        "        history[\"valid_acc\"].append(valid_acc)\n",
        "        history[\"valid_preds_list\"].append(valid_preds_list)\n",
        "        history[\"valid_truelabels_list\"].append(valid_truelabels_list)\n",
        "        history[\"valid_probas_list\"].append(valid_probas_list)\n",
        "        history[\"valid_auc_score\"].append(valid_auc_score)\n",
        "\n",
        "        print('{}: loss: {:.4f} acc: {:.4f} auc: {:.4f}'.format('validation', valid_loss, valid_acc, valid_auc_score))\n",
        "        print()\n",
        "\n",
        "        # save models(use valid loss as best model criterion, please change\n",
        "        # criterion here if needed(eg. valid acc)\n",
        "        is_best = valid_loss < best_val_loss\n",
        "        best_val_loss = min(valid_loss, best_val_loss)\n",
        "\n",
        "        if is_best:\n",
        "            # please change model file path here\n",
        "            best_model_file = \"best_models/best_dry_run1.pth\"\n",
        "            torch.save(model.state_dict(), best_model_file)\n",
        "\n",
        "        # save model from every training epoch\n",
        "        # can be deleted if do not need this one, or adapt it to save 5th, 10th, 15th ...models\n",
        "        model_file = \"best_models/dry_run1\" + str(epoch) + \".pth\"\n",
        "\n",
        "        torch.save(model.state_dict(), model_file)\n",
        "\n",
        "        # save training/validation results\n",
        "        with open(\"history.pkl\", \"wb\") as fout:\n",
        "            pickle.dump(history, fout)\n",
        "\n",
        "    print('time elapsed:', time.time() - start_time)\n",
        "\n",
        "    return history\n",
        "\n",
        "results = train_valid()\n",
        "\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "###################################\n",
            "############## Train ##############\n",
            "###################################\n",
            "epoch:  1\n",
            "training: loss: 4.7862 acc: 0.0135\n",
            "validation: loss: 4.7868 acc: 0.0146 auc: 0.5037\n",
            "\n",
            "epoch:  2\n",
            "training: loss: 4.7811 acc: 0.0200\n",
            "validation: loss: 4.7812 acc: 0.0194 auc: 0.5076\n",
            "\n",
            "epoch:  3\n",
            "training: loss: 4.7766 acc: 0.0242\n",
            "validation: loss: 4.7795 acc: 0.0224 auc: 0.5118\n",
            "\n",
            "epoch:  4\n",
            "training: loss: 4.7716 acc: 0.0284\n",
            "validation: loss: 4.7743 acc: 0.0267 auc: 0.5124\n",
            "\n",
            "epoch:  5\n",
            "training: loss: 4.7670 acc: 0.0341\n",
            "validation: loss: 4.7766 acc: 0.0258 auc: 0.5107\n",
            "\n",
            "epoch:  6\n",
            "training: loss: 4.7630 acc: 0.0387\n",
            "validation: loss: 4.7743 acc: 0.0267 auc: 0.5133\n",
            "\n",
            "epoch:  7\n",
            "training: loss: 4.7615 acc: 0.0392\n",
            "validation: loss: 4.7745 acc: 0.0243 auc: 0.5127\n",
            "\n",
            "epoch:  8\n",
            "training: loss: 4.7594 acc: 0.0416\n",
            "validation: loss: 4.7732 acc: 0.0258 auc: 0.5130\n",
            "\n",
            "epoch:  9\n",
            "training: loss: 4.7563 acc: 0.0452\n",
            "validation: loss: 4.7714 acc: 0.0282 auc: 0.5181\n",
            "\n",
            "epoch:  10\n",
            "training: loss: 4.7553 acc: 0.0460\n",
            "validation: loss: 4.7748 acc: 0.0258 auc: 0.5153\n",
            "\n",
            "epoch:  11\n",
            "training: loss: 4.7515 acc: 0.0498\n",
            "validation: loss: 4.7734 acc: 0.0277 auc: 0.5152\n",
            "\n",
            "epoch:  12\n",
            "training: loss: 4.7514 acc: 0.0497\n",
            "validation: loss: 4.7725 acc: 0.0282 auc: 0.5148\n",
            "\n",
            "epoch:  13\n",
            "training: loss: 4.7475 acc: 0.0544\n",
            "validation: loss: 4.7721 acc: 0.0282 auc: 0.5165\n",
            "\n",
            "epoch:  14\n",
            "training: loss: 4.7461 acc: 0.0553\n",
            "validation: loss: 4.7724 acc: 0.0282 auc: 0.5152\n",
            "\n",
            "epoch:  15\n",
            "training: loss: 4.7433 acc: 0.0584\n",
            "validation: loss: 4.7722 acc: 0.0287 auc: 0.5140\n",
            "\n",
            "epoch:  16\n",
            "training: loss: 4.7414 acc: 0.0596\n",
            "validation: loss: 4.7699 acc: 0.0311 auc: 0.5177\n",
            "\n",
            "epoch:  17\n",
            "training: loss: 4.7397 acc: 0.0621\n",
            "validation: loss: 4.7733 acc: 0.0262 auc: 0.5187\n",
            "\n",
            "epoch:  18\n",
            "training: loss: 4.7366 acc: 0.0652\n",
            "validation: loss: 4.7691 acc: 0.0311 auc: 0.5173\n",
            "\n",
            "epoch:  19\n",
            "training: loss: 4.7376 acc: 0.0640\n",
            "validation: loss: 4.7697 acc: 0.0301 auc: 0.5178\n",
            "\n",
            "epoch:  20\n",
            "training: loss: 4.7352 acc: 0.0668\n",
            "validation: loss: 4.7656 acc: 0.0345 auc: 0.5192\n",
            "\n",
            "time elapsed: 2076.2739493846893\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-7-HCPvbjwz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fcce8f5b-acc5-4fa3-9733-1b1ccd70bfeb"
      },
      "source": [
        "print(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OTtFZwPoprx3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "6b4bbf94-a6d1-4692-98b1-5d5e822d027e"
      },
      "source": [
        "#Load eigenvalues and eigenvectors\n",
        "\n",
        "(eig_vals,eig_image_list) = pickle.load( open( \"eigvalsvecs.p\", \"rb\" ) )"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-a05a53aba823>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Load eigenvalues and eigenvectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0meig_vals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0meig_image_list\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"eigvalsvecs.p\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'eigvalsvecs.p'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHpCcTHgprx-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# turn eigenvectors from list into matrix\n",
        "eig_vec_mat = np.zeros((eig_vec_list[0].shape[0]*(eig_vec_list[0].shape[1]),len(eig_vec_list)))\n",
        "for ii,vec in enumerate(eig_vec_list):\n",
        "    eig_vec_mat[:,ii] = unravel_image(vec)\n",
        "  \n",
        "    \n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APkl-KHDpryG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eig_vec_mat.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvFOIwDBpryS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###################################\n",
        "############## Test ###############\n",
        "###################################\n",
        "print('###################################')\n",
        "print('############# Test ################')\n",
        "print('###################################')\n",
        "\n",
        "def test(optimizer = optim.Adam(model.parameters()), model = model,  test_criterion = nn.CrossEntropyLoss(),\n",
        "         loader = test_loader, device = device):\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total_samples = 0\n",
        "    correct = 0\n",
        "    mysoftmax = nn.Softmax(dim=1)\n",
        "\n",
        "    preds_list = []\n",
        "    truelabels_list = []\n",
        "    probas_list = []\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, samples in enumerate(loader):\n",
        "\n",
        "            image = samples['image'].to(device)\n",
        "            label = samples['label'].squeeze()\n",
        "            label = torch.tensor(label, dtype=torch.long, device=device)\n",
        "\n",
        "            output = model(image)\n",
        "            output_softmax = mysoftmax(output)\n",
        "\n",
        "            _, preds = torch.max(output, dim = 1)\n",
        "\n",
        "            loss = test_criterion(output, label)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            total_samples += image.shape[0]\n",
        "            correct += torch.sum(preds == label).item()\n",
        "\n",
        "\n",
        "            preds_list.append(preds.cpu().numpy())\n",
        "            truelabels_list.append(label.cpu().numpy())\n",
        "            probas_list.append(output_softmax.cpu().numpy())\n",
        "\n",
        "        test_accuracy = correct / total_samples\n",
        "\n",
        "        return running_loss / len(loader), test_accuracy, preds_list, truelabels_list, probas_list\n",
        "\n",
        "\n",
        "test_loss, test_acc,  preds_list, truelabels_list, probas_list= test()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5baQz8RepryY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}