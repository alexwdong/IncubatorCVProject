{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision.transforms import ToTensor,Resize,Compose\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.train_valid import train, validation\n",
    "from src.Basic_CNN_Architecture import ResNet, ResidualBlock\n",
    "from src.data_loader import load_dog_data,SquarePadding\n",
    "from src.utils import unravel_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 GPU(s) available.\n",
      "We will use the GPU: GeForce RTX 2060 SUPER\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "\n",
    "    # Tell PyTorch to use the GPU.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
    "\n",
    "# If not...\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_df_path =\n",
    "#test_df_path =\n",
    "#root_dir =\n",
    "\n",
    "\n",
    "\n",
    "#Put your data path here\n",
    "data_path = r'C:\\Users\\Alec\\Documents\\GitHub\\IncubatorCVProject\\DogsDataset\\images\\Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "############ load data ############\n",
    "###################################\n",
    "\n",
    "# after feature engineering(task 3)\n",
    "\n",
    "#Variables for splitting the dataset into train/test\n",
    "valid_split = .1\n",
    "test_split = .1\n",
    "batch_size = 16\n",
    "shuffle_dataset = True\n",
    "random_seed = 42\n",
    "\n",
    "#Load initial dataset\n",
    "dog_dataset = ImageFolder(data_path,transform=Compose([\n",
    "    SquarePadding(),\n",
    "    Resize((128,128)),\n",
    "    ToTensor()\n",
    "])) \n",
    "# Split \n",
    "dataset_size = len(dog_dataset)\n",
    "indices = list(range(dataset_size))\n",
    "split_idx1 = int(np.floor((valid_split+test_split) * dataset_size))\n",
    "split_idx2 = int(np.floor(test_split * dataset_size))\n",
    "if shuffle_dataset:\n",
    "    np.random.seed(random_seed)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "test_indices, valid_indices, train_indices = indices[:split_idx2], indices[split_idx2:split_idx1], indices[split_idx1:]\n",
    "\n",
    "# Creating PT data samplers and loaders:\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(valid_indices)\n",
    "test_sampler = SubsetRandomSampler(test_indices)\n",
    "\n",
    "#Load Train, valid, test          \n",
    "train_loader = torch.utils.data.DataLoader(dog_dataset, batch_size=batch_size, \n",
    "                                           sampler=train_sampler)\n",
    "valid_loader = torch.utils.data.DataLoader(dog_dataset, batch_size=batch_size,\n",
    "                                                sampler=valid_sampler)\n",
    "test_loader =  torch.utils.data.DataLoader(dog_dataset, batch_size=batch_size,\n",
    "                                                sampler=test_sampler)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###################################\n",
      "############## Train ##############\n",
      "###################################\n",
      "epoch:  1\n",
      "training: loss: 4.7932 acc: 0.0085\n",
      "validation: loss: 4.7956 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  2\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  3\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7956 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  4\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  5\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  6\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  7\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  8\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  9\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  10\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  11\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  12\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  13\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n",
      "epoch:  14\n",
      "training: loss: 4.7931 acc: 0.0086\n",
      "validation: loss: 4.7959 acc: 0.0058 auc: 0.5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "############ Train ############\n",
    "###################################\n",
    "print('###################################')\n",
    "print('############## Train ##############')\n",
    "print('###################################')\n",
    "\n",
    "# training process\n",
    "# to be finished later\n",
    "model = ResNet(\n",
    "    ResidualBlock,\n",
    "    in_channels = 3,\n",
    "    conv1_out_channels = 64,\n",
    "    conv2_out_channels = 128,\n",
    "    num_blocks = 20,\n",
    "    lin1_out_channels = 128,\n",
    "    num_classes=len(dog_dataset.classes),\n",
    "    kernel_size = 5,\n",
    "    stride = 2,\n",
    "    padding = 2\n",
    "                        )\n",
    "model.to(device)\n",
    "\n",
    "def train_valid(optimizer = optim.Adam(model.parameters()), epochs = 20, model = model,\n",
    "                train_criterion = nn.CrossEntropyLoss(), train_loader = train_loader,\n",
    "                valid_criterion = nn.CrossEntropyLoss(), valid_loader = valid_loader,\n",
    "                device = device):\n",
    "\n",
    "    start_epoch = 1\n",
    "    #or: best_val_acc = 0\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    history = {\"train_loss\":[], \"train_acc\":[],\n",
    "                \"valid_loss\":[], \"valid_acc\":[], \"valid_preds_list\":[],\n",
    "                \"valid_truelabels_list\":[], \"valid_probas_list\":[], \"valid_auc_score\":[]}\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    for epoch in range(start_epoch, epochs + 1):\n",
    "\n",
    "        train_loss, train_acc = train(epoch, model, optimizer, train_criterion, train_loader, device)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "\n",
    "        print('epoch: ', epoch)\n",
    "        print('{}: loss: {:.4f} acc: {:.4f}'.format('training', train_loss, train_acc))\n",
    "\n",
    "        valid_loss, valid_acc, valid_preds_list, valid_truelabels_list, valid_probas_list, valid_auc_score = validation(epoch, model, optimizer, valid_criterion, valid_loader, device)\n",
    "        history[\"valid_loss\"].append(valid_loss)\n",
    "        history[\"valid_acc\"].append(valid_acc)\n",
    "        history[\"valid_preds_list\"].append(valid_preds_list)\n",
    "        history[\"valid_truelabels_list\"].append(valid_truelabels_list)\n",
    "        history[\"valid_probas_list\"].append(valid_probas_list)\n",
    "        history[\"valid_auc_score\"].append(valid_auc_score)\n",
    "\n",
    "        print('{}: loss: {:.4f} acc: {:.4f} auc: {:.4f}\\n'.format('validation', valid_loss, valid_acc, valid_auc_score))\n",
    "\n",
    "\n",
    "    return history\n",
    "\n",
    "results = train_valid()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
